Using device: cuda
Training Simple Neural Network (SNN)...
Epoch [1/200], Loss: 1.7726
Epoch [2/200], Loss: 0.7967
Epoch [3/200], Loss: 0.5398
Epoch [4/200], Loss: 0.4516
Epoch [5/200], Loss: 0.4066
Epoch [6/200], Loss: 0.3790
Epoch [7/200], Loss: 0.3595
Epoch [8/200], Loss: 0.3448
Epoch [9/200], Loss: 0.3327
Epoch [10/200], Loss: 0.3225
Epoch [11/200], Loss: 0.3135
Epoch [12/200], Loss: 0.3056
Epoch [13/200], Loss: 0.2984
Epoch [14/200], Loss: 0.2918
Epoch [15/200], Loss: 0.2853
Epoch [16/200], Loss: 0.2793
Epoch [17/200], Loss: 0.2737
Epoch [18/200], Loss: 0.2681
Epoch [19/200], Loss: 0.2629
Epoch [20/200], Loss: 0.2580
Epoch [21/200], Loss: 0.2531
Epoch [22/200], Loss: 0.2483
Epoch [23/200], Loss: 0.2439
Epoch [24/200], Loss: 0.2396
Epoch [25/200], Loss: 0.2353
Epoch [26/200], Loss: 0.2313
Epoch [27/200], Loss: 0.2273
Epoch [28/200], Loss: 0.2236
Epoch [29/200], Loss: 0.2199
Epoch [30/200], Loss: 0.2165
Epoch [31/200], Loss: 0.2129
Epoch [32/200], Loss: 0.2095
Epoch [33/200], Loss: 0.2064
Epoch [34/200], Loss: 0.2032
Epoch [35/200], Loss: 0.2002
Epoch [36/200], Loss: 0.1973
Epoch [37/200], Loss: 0.1945
Epoch [38/200], Loss: 0.1916
Epoch [39/200], Loss: 0.1889
Epoch [40/200], Loss: 0.1864
Epoch [41/200], Loss: 0.1838
Epoch [42/200], Loss: 0.1813
Epoch [43/200], Loss: 0.1789
Epoch [44/200], Loss: 0.1764
Epoch [45/200], Loss: 0.1742
Epoch [46/200], Loss: 0.1718
Epoch [47/200], Loss: 0.1698
Epoch [48/200], Loss: 0.1675
Epoch [49/200], Loss: 0.1654
Epoch [50/200], Loss: 0.1634
Epoch [51/200], Loss: 0.1614
Epoch [52/200], Loss: 0.1593
Epoch [53/200], Loss: 0.1575
Epoch [54/200], Loss: 0.1556
Epoch [55/200], Loss: 0.1538
Epoch [56/200], Loss: 0.1519
Epoch [57/200], Loss: 0.1501
Epoch [58/200], Loss: 0.1487
Epoch [59/200], Loss: 0.1468
Epoch [60/200], Loss: 0.1452
Epoch [61/200], Loss: 0.1436
Epoch [62/200], Loss: 0.1421
Epoch [63/200], Loss: 0.1405
Epoch [64/200], Loss: 0.1390
Epoch [65/200], Loss: 0.1375
Epoch [66/200], Loss: 0.1360
Epoch [67/200], Loss: 0.1346
Epoch [68/200], Loss: 0.1332
Epoch [69/200], Loss: 0.1318
Epoch [70/200], Loss: 0.1305
Epoch [71/200], Loss: 0.1292
Epoch [72/200], Loss: 0.1279
Epoch [73/200], Loss: 0.1266
Epoch [74/200], Loss: 0.1254
Epoch [75/200], Loss: 0.1241
Epoch [76/200], Loss: 0.1229
Epoch [77/200], Loss: 0.1217
Epoch [78/200], Loss: 0.1206
Epoch [79/200], Loss: 0.1195
Epoch [80/200], Loss: 0.1183
Epoch [81/200], Loss: 0.1172
Epoch [82/200], Loss: 0.1162
Epoch [83/200], Loss: 0.1151
Epoch [84/200], Loss: 0.1141
Epoch [85/200], Loss: 0.1130
Epoch [86/200], Loss: 0.1120
Epoch [87/200], Loss: 0.1111
Epoch [88/200], Loss: 0.1101
Epoch [89/200], Loss: 0.1091
Epoch [90/200], Loss: 0.1081
Epoch [91/200], Loss: 0.1072
Epoch [92/200], Loss: 0.1063
Epoch [93/200], Loss: 0.1054
Epoch [94/200], Loss: 0.1046
Epoch [95/200], Loss: 0.1036
Epoch [96/200], Loss: 0.1028
Epoch [97/200], Loss: 0.1019
Epoch [98/200], Loss: 0.1011
Epoch [99/200], Loss: 0.1002
Epoch [100/200], Loss: 0.0995
Epoch [101/200], Loss: 0.0987
Epoch [102/200], Loss: 0.0979
Epoch [103/200], Loss: 0.0971
Epoch [104/200], Loss: 0.0964
Epoch [105/200], Loss: 0.0956
Epoch [106/200], Loss: 0.0948
Epoch [107/200], Loss: 0.0941
Epoch [108/200], Loss: 0.0934
Epoch [109/200], Loss: 0.0927
Epoch [110/200], Loss: 0.0919
Epoch [111/200], Loss: 0.0913
Epoch [112/200], Loss: 0.0906
Epoch [113/200], Loss: 0.0899
Epoch [114/200], Loss: 0.0892
Epoch [115/200], Loss: 0.0886
Epoch [116/200], Loss: 0.0879
Epoch [117/200], Loss: 0.0873
Epoch [118/200], Loss: 0.0867
Epoch [119/200], Loss: 0.0861
Epoch [120/200], Loss: 0.0855
Epoch [121/200], Loss: 0.0849
Epoch [122/200], Loss: 0.0843
Epoch [123/200], Loss: 0.0837
Epoch [124/200], Loss: 0.0831
Epoch [125/200], Loss: 0.0825
Epoch [126/200], Loss: 0.0820
Epoch [127/200], Loss: 0.0814
Epoch [128/200], Loss: 0.0807
Epoch [129/200], Loss: 0.0803
Epoch [130/200], Loss: 0.0797
Epoch [131/200], Loss: 0.0792
Epoch [132/200], Loss: 0.0786
Epoch [133/200], Loss: 0.0782
Epoch [134/200], Loss: 0.0777
Epoch [135/200], Loss: 0.0771
Epoch [136/200], Loss: 0.0766
Epoch [137/200], Loss: 0.0762
Epoch [138/200], Loss: 0.0757
Epoch [139/200], Loss: 0.0752
Epoch [140/200], Loss: 0.0746
Epoch [141/200], Loss: 0.0743
Epoch [142/200], Loss: 0.0737
Epoch [143/200], Loss: 0.0733
Epoch [144/200], Loss: 0.0728
Epoch [145/200], Loss: 0.0724
Epoch [146/200], Loss: 0.0719
Epoch [147/200], Loss: 0.0715
Epoch [148/200], Loss: 0.0711
Epoch [149/200], Loss: 0.0706
Epoch [150/200], Loss: 0.0702
Epoch [151/200], Loss: 0.0697
Epoch [152/200], Loss: 0.0693
Epoch [153/200], Loss: 0.0689
Epoch [154/200], Loss: 0.0685
Epoch [155/200], Loss: 0.0681
Epoch [156/200], Loss: 0.0677
Epoch [157/200], Loss: 0.0673
Epoch [158/200], Loss: 0.0669
Epoch [159/200], Loss: 0.0665
Epoch [160/200], Loss: 0.0661
Epoch [161/200], Loss: 0.0657
Epoch [162/200], Loss: 0.0653
Epoch [163/200], Loss: 0.0649
Epoch [164/200], Loss: 0.0645
Epoch [165/200], Loss: 0.0642
Epoch [166/200], Loss: 0.0639
Epoch [167/200], Loss: 0.0635
Epoch [168/200], Loss: 0.0631
Epoch [169/200], Loss: 0.0628
Epoch [170/200], Loss: 0.0625
Epoch [171/200], Loss: 0.0621
Epoch [172/200], Loss: 0.0618
Epoch [173/200], Loss: 0.0613
Epoch [174/200], Loss: 0.0610
Epoch [175/200], Loss: 0.0607
Epoch [176/200], Loss: 0.0603
Epoch [177/200], Loss: 0.0601
Epoch [178/200], Loss: 0.0597
Epoch [179/200], Loss: 0.0594
Epoch [180/200], Loss: 0.0591
Epoch [181/200], Loss: 0.0587
Epoch [182/200], Loss: 0.0585
Epoch [183/200], Loss: 0.0581
Epoch [184/200], Loss: 0.0578
Epoch [185/200], Loss: 0.0575
Epoch [186/200], Loss: 0.0572
Epoch [187/200], Loss: 0.0569
Epoch [188/200], Loss: 0.0566
Epoch [189/200], Loss: 0.0563
Epoch [190/200], Loss: 0.0560
Epoch [191/200], Loss: 0.0557
Epoch [192/200], Loss: 0.0554
Epoch [193/200], Loss: 0.0552
Epoch [194/200], Loss: 0.0549
Epoch [195/200], Loss: 0.0546
Epoch [196/200], Loss: 0.0543
Epoch [197/200], Loss: 0.0540
Epoch [198/200], Loss: 0.0537
Epoch [199/200], Loss: 0.0535
Epoch [200/200], Loss: 0.0532

Training Deep Neural Network without Regularization (DNN)...
Epoch [1/200], Loss: 2.2900
Epoch [2/200], Loss: 2.1475
Epoch [3/200], Loss: 1.3504
Epoch [4/200], Loss: 0.7008
Epoch [5/200], Loss: 0.5202
Epoch [6/200], Loss: 0.4425
Epoch [7/200], Loss: 0.3964
Epoch [8/200], Loss: 0.3647
Epoch [9/200], Loss: 0.3419
Epoch [10/200], Loss: 0.3215
Epoch [11/200], Loss: 0.3041
Epoch [12/200], Loss: 0.2887
Epoch [13/200], Loss: 0.2731
Epoch [14/200], Loss: 0.2585
Epoch [15/200], Loss: 0.2451
Epoch [16/200], Loss: 0.2319
Epoch [17/200], Loss: 0.2206
Epoch [18/200], Loss: 0.2085
Epoch [19/200], Loss: 0.1988
Epoch [20/200], Loss: 0.1901
Epoch [21/200], Loss: 0.1810
Epoch [22/200], Loss: 0.1733
Epoch [23/200], Loss: 0.1664
Epoch [24/200], Loss: 0.1597
Epoch [25/200], Loss: 0.1531
Epoch [26/200], Loss: 0.1477
Epoch [27/200], Loss: 0.1421
Epoch [28/200], Loss: 0.1369
Epoch [29/200], Loss: 0.1326
Epoch [30/200], Loss: 0.1282
Epoch [31/200], Loss: 0.1242
Epoch [32/200], Loss: 0.1200
Epoch [33/200], Loss: 0.1161
Epoch [34/200], Loss: 0.1125
Epoch [35/200], Loss: 0.1094
Epoch [36/200], Loss: 0.1055
Epoch [37/200], Loss: 0.1029
Epoch [38/200], Loss: 0.0999
Epoch [39/200], Loss: 0.0964
Epoch [40/200], Loss: 0.0940
Epoch [41/200], Loss: 0.0914
Epoch [42/200], Loss: 0.0883
Epoch [43/200], Loss: 0.0860
Epoch [44/200], Loss: 0.0835
Epoch [45/200], Loss: 0.0813
Epoch [46/200], Loss: 0.0791
Epoch [47/200], Loss: 0.0766
Epoch [48/200], Loss: 0.0749
Epoch [49/200], Loss: 0.0728
Epoch [50/200], Loss: 0.0706
Epoch [51/200], Loss: 0.0687
Epoch [52/200], Loss: 0.0668
Epoch [53/200], Loss: 0.0654
Epoch [54/200], Loss: 0.0633
Epoch [55/200], Loss: 0.0616
Epoch [56/200], Loss: 0.0600
Epoch [57/200], Loss: 0.0584
Epoch [58/200], Loss: 0.0570
Epoch [59/200], Loss: 0.0554
Epoch [60/200], Loss: 0.0540
Epoch [61/200], Loss: 0.0526
Epoch [62/200], Loss: 0.0511
Epoch [63/200], Loss: 0.0501
Epoch [64/200], Loss: 0.0489
Epoch [65/200], Loss: 0.0472
Epoch [66/200], Loss: 0.0459
Epoch [67/200], Loss: 0.0450
Epoch [68/200], Loss: 0.0439
Epoch [69/200], Loss: 0.0426
Epoch [70/200], Loss: 0.0418
Epoch [71/200], Loss: 0.0405
Epoch [72/200], Loss: 0.0396
Epoch [73/200], Loss: 0.0386
Epoch [74/200], Loss: 0.0375
Epoch [75/200], Loss: 0.0363
Epoch [76/200], Loss: 0.0356
Epoch [77/200], Loss: 0.0345
Epoch [78/200], Loss: 0.0338
Epoch [79/200], Loss: 0.0329
Epoch [80/200], Loss: 0.0321
Epoch [81/200], Loss: 0.0315
Epoch [82/200], Loss: 0.0304
Epoch [83/200], Loss: 0.0295
Epoch [84/200], Loss: 0.0288
Epoch [85/200], Loss: 0.0281
Epoch [86/200], Loss: 0.0274
Epoch [87/200], Loss: 0.0269
Epoch [88/200], Loss: 0.0261
Epoch [89/200], Loss: 0.0255
Epoch [90/200], Loss: 0.0248
Epoch [91/200], Loss: 0.0242
Epoch [92/200], Loss: 0.0235
Epoch [93/200], Loss: 0.0230
Epoch [94/200], Loss: 0.0222
Epoch [95/200], Loss: 0.0217
Epoch [96/200], Loss: 0.0212
Epoch [97/200], Loss: 0.0206
Epoch [98/200], Loss: 0.0201
Epoch [99/200], Loss: 0.0199
Epoch [100/200], Loss: 0.0190
Epoch [101/200], Loss: 0.0186
Epoch [102/200], Loss: 0.0182
Epoch [103/200], Loss: 0.0179
Epoch [104/200], Loss: 0.0173
Epoch [105/200], Loss: 0.0168
Epoch [106/200], Loss: 0.0165
Epoch [107/200], Loss: 0.0160
Epoch [108/200], Loss: 0.0158
Epoch [109/200], Loss: 0.0153
Epoch [110/200], Loss: 0.0149
Epoch [111/200], Loss: 0.0145
Epoch [112/200], Loss: 0.0143
Epoch [113/200], Loss: 0.0139
Epoch [114/200], Loss: 0.0137
Epoch [115/200], Loss: 0.0132
Epoch [116/200], Loss: 0.0129
Epoch [117/200], Loss: 0.0125
Epoch [118/200], Loss: 0.0125
Epoch [119/200], Loss: 0.0120
Epoch [120/200], Loss: 0.0117
Epoch [121/200], Loss: 0.0114
Epoch [122/200], Loss: 0.0111
Epoch [123/200], Loss: 0.0112
Epoch [124/200], Loss: 0.0107
Epoch [125/200], Loss: 0.0105
Epoch [126/200], Loss: 0.0103
Epoch [127/200], Loss: 0.0101
Epoch [128/200], Loss: 0.0098
Epoch [129/200], Loss: 0.0095
Epoch [130/200], Loss: 0.0094
Epoch [131/200], Loss: 0.0091
Epoch [132/200], Loss: 0.0090
Epoch [133/200], Loss: 0.0088
Epoch [134/200], Loss: 0.0085
Epoch [135/200], Loss: 0.0084
Epoch [136/200], Loss: 0.0081
Epoch [137/200], Loss: 0.0080
Epoch [138/200], Loss: 0.0078
Epoch [139/200], Loss: 0.0077
Epoch [140/200], Loss: 0.0075
Epoch [141/200], Loss: 0.0074
Epoch [142/200], Loss: 0.0072
Epoch [143/200], Loss: 0.0070
Epoch [144/200], Loss: 0.0069
Epoch [145/200], Loss: 0.0067
Epoch [146/200], Loss: 0.0067
Epoch [147/200], Loss: 0.0065
Epoch [148/200], Loss: 0.0063
Epoch [149/200], Loss: 0.0062
Epoch [150/200], Loss: 0.0061
Epoch [151/200], Loss: 0.0060
Epoch [152/200], Loss: 0.0058
Epoch [153/200], Loss: 0.0057
Epoch [154/200], Loss: 0.0056
Epoch [155/200], Loss: 0.0054
Epoch [156/200], Loss: 0.0054
Epoch [157/200], Loss: 0.0053
Epoch [158/200], Loss: 0.0051
Epoch [159/200], Loss: 0.0051
Epoch [160/200], Loss: 0.0050
Epoch [161/200], Loss: 0.0048
Epoch [162/200], Loss: 0.0048
Epoch [163/200], Loss: 0.0047
Epoch [164/200], Loss: 0.0046
Epoch [165/200], Loss: 0.0044
Epoch [166/200], Loss: 0.0044
Epoch [167/200], Loss: 0.0043
Epoch [168/200], Loss: 0.0042
Epoch [169/200], Loss: 0.0042
Epoch [170/200], Loss: 0.0041
Epoch [171/200], Loss: 0.0040
Epoch [172/200], Loss: 0.0040
Epoch [173/200], Loss: 0.0039
Epoch [174/200], Loss: 0.0038
Epoch [175/200], Loss: 0.0037
Epoch [176/200], Loss: 0.0037
Epoch [177/200], Loss: 0.0036
Epoch [178/200], Loss: 0.0035
Epoch [179/200], Loss: 0.0035
Epoch [180/200], Loss: 0.0034
Epoch [181/200], Loss: 0.0034
Epoch [182/200], Loss: 0.0033
Epoch [183/200], Loss: 0.0032
Epoch [184/200], Loss: 0.0032
Epoch [185/200], Loss: 0.0031
Epoch [186/200], Loss: 0.0031
Epoch [187/200], Loss: 0.0030
Epoch [188/200], Loss: 0.0030
Epoch [189/200], Loss: 0.0029
Epoch [190/200], Loss: 0.0029
Epoch [191/200], Loss: 0.0028
Epoch [192/200], Loss: 0.0028
Epoch [193/200], Loss: 0.0027
Epoch [194/200], Loss: 0.0027
Epoch [195/200], Loss: 0.0027
Epoch [196/200], Loss: 0.0026
Epoch [197/200], Loss: 0.0026
Epoch [198/200], Loss: 0.0025
Epoch [199/200], Loss: 0.0025
Epoch [200/200], Loss: 0.0025

Training Deep Neural Network with L2 Regularization (DNN-Reg)...
Epoch [1/200], Loss: 2.2962
Epoch [2/200], Loss: 2.2529
Epoch [3/200], Loss: 1.9195
Epoch [4/200], Loss: 0.9857
Epoch [5/200], Loss: 0.6108
Epoch [6/200], Loss: 0.4809
Epoch [7/200], Loss: 0.4215
Epoch [8/200], Loss: 0.3863
Epoch [9/200], Loss: 0.3598
Epoch [10/200], Loss: 0.3396
Epoch [11/200], Loss: 0.3221
Epoch [12/200], Loss: 0.3066
Epoch [13/200], Loss: 0.2924
Epoch [14/200], Loss: 0.2799
Epoch [15/200], Loss: 0.2672
Epoch [16/200], Loss: 0.2550
Epoch [17/200], Loss: 0.2440
Epoch [18/200], Loss: 0.2327
Epoch [19/200], Loss: 0.2226
Epoch [20/200], Loss: 0.2129
Epoch [21/200], Loss: 0.2041
Epoch [22/200], Loss: 0.1955
Epoch [23/200], Loss: 0.1871
Epoch [24/200], Loss: 0.1802
Epoch [25/200], Loss: 0.1735
Epoch [26/200], Loss: 0.1674
Epoch [27/200], Loss: 0.1617
Epoch [28/200], Loss: 0.1560
Epoch [29/200], Loss: 0.1507
Epoch [30/200], Loss: 0.1460
Epoch [31/200], Loss: 0.1417
Epoch [32/200], Loss: 0.1375
Epoch [33/200], Loss: 0.1332
Epoch [34/200], Loss: 0.1296
Epoch [35/200], Loss: 0.1262
Epoch [36/200], Loss: 0.1227
Epoch [37/200], Loss: 0.1193
Epoch [38/200], Loss: 0.1164
Epoch [39/200], Loss: 0.1130
Epoch [40/200], Loss: 0.1109
Epoch [41/200], Loss: 0.1075
Epoch [42/200], Loss: 0.1049
Epoch [43/200], Loss: 0.1026
Epoch [44/200], Loss: 0.1001
Epoch [45/200], Loss: 0.0979
Epoch [46/200], Loss: 0.0955
Epoch [47/200], Loss: 0.0932
Epoch [48/200], Loss: 0.0916
Epoch [49/200], Loss: 0.0893
Epoch [50/200], Loss: 0.0875
Epoch [51/200], Loss: 0.0859
Epoch [52/200], Loss: 0.0840
Epoch [53/200], Loss: 0.0822
Epoch [54/200], Loss: 0.0804
Epoch [55/200], Loss: 0.0788
Epoch [56/200], Loss: 0.0774
Epoch [57/200], Loss: 0.0759
Epoch [58/200], Loss: 0.0743
Epoch [59/200], Loss: 0.0729
Epoch [60/200], Loss: 0.0719
Epoch [61/200], Loss: 0.0704
Epoch [62/200], Loss: 0.0694
Epoch [63/200], Loss: 0.0681
Epoch [64/200], Loss: 0.0664
Epoch [65/200], Loss: 0.0656
Epoch [66/200], Loss: 0.0642
Epoch [67/200], Loss: 0.0634
Epoch [68/200], Loss: 0.0623
Epoch [69/200], Loss: 0.0614
Epoch [70/200], Loss: 0.0601
Epoch [71/200], Loss: 0.0592
Epoch [72/200], Loss: 0.0583
Epoch [73/200], Loss: 0.0574
Epoch [74/200], Loss: 0.0564
Epoch [75/200], Loss: 0.0553
Epoch [76/200], Loss: 0.0546
Epoch [77/200], Loss: 0.0539
Epoch [78/200], Loss: 0.0529
Epoch [79/200], Loss: 0.0522
Epoch [80/200], Loss: 0.0515
Epoch [81/200], Loss: 0.0508
Epoch [82/200], Loss: 0.0501
Epoch [83/200], Loss: 0.0492
Epoch [84/200], Loss: 0.0487
Epoch [85/200], Loss: 0.0478
Epoch [86/200], Loss: 0.0471
Epoch [87/200], Loss: 0.0466
Epoch [88/200], Loss: 0.0459
Epoch [89/200], Loss: 0.0452
Epoch [90/200], Loss: 0.0447
Epoch [91/200], Loss: 0.0441
Epoch [92/200], Loss: 0.0433
Epoch [93/200], Loss: 0.0428
Epoch [94/200], Loss: 0.0425
Epoch [95/200], Loss: 0.0417
Epoch [96/200], Loss: 0.0412
Epoch [97/200], Loss: 0.0406
Epoch [98/200], Loss: 0.0401
Epoch [99/200], Loss: 0.0397
Epoch [100/200], Loss: 0.0393
Epoch [101/200], Loss: 0.0387
Epoch [102/200], Loss: 0.0383
Epoch [103/200], Loss: 0.0378
Epoch [104/200], Loss: 0.0373
Epoch [105/200], Loss: 0.0370
Epoch [106/200], Loss: 0.0365
Epoch [107/200], Loss: 0.0360
Epoch [108/200], Loss: 0.0355
Epoch [109/200], Loss: 0.0352
Epoch [110/200], Loss: 0.0348
Epoch [111/200], Loss: 0.0345
Epoch [112/200], Loss: 0.0343
Epoch [113/200], Loss: 0.0338
Epoch [114/200], Loss: 0.0335
Epoch [115/200], Loss: 0.0331
Epoch [116/200], Loss: 0.0328
Epoch [117/200], Loss: 0.0322
Epoch [118/200], Loss: 0.0321
Epoch [119/200], Loss: 0.0317
Epoch [120/200], Loss: 0.0315
Epoch [121/200], Loss: 0.0313
Epoch [122/200], Loss: 0.0307
Epoch [123/200], Loss: 0.0305
Epoch [124/200], Loss: 0.0303
Epoch [125/200], Loss: 0.0301
Epoch [126/200], Loss: 0.0296
Epoch [127/200], Loss: 0.0295
Epoch [128/200], Loss: 0.0291
Epoch [129/200], Loss: 0.0288
Epoch [130/200], Loss: 0.0287
Epoch [131/200], Loss: 0.0283
Epoch [132/200], Loss: 0.0280
Epoch [133/200], Loss: 0.0279
Epoch [134/200], Loss: 0.0275
Epoch [135/200], Loss: 0.0275
Epoch [136/200], Loss: 0.0272
Epoch [137/200], Loss: 0.0269
Epoch [138/200], Loss: 0.0267
Epoch [139/200], Loss: 0.0265
Epoch [140/200], Loss: 0.0263
Epoch [141/200], Loss: 0.0260
Epoch [142/200], Loss: 0.0259
Epoch [143/200], Loss: 0.0256
Epoch [144/200], Loss: 0.0255
Epoch [145/200], Loss: 0.0253
Epoch [146/200], Loss: 0.0252
Epoch [147/200], Loss: 0.0249
Epoch [148/200], Loss: 0.0248
Epoch [149/200], Loss: 0.0245
Epoch [150/200], Loss: 0.0245
Epoch [151/200], Loss: 0.0242
Epoch [152/200], Loss: 0.0241
Epoch [153/200], Loss: 0.0239
Epoch [154/200], Loss: 0.0237
Epoch [155/200], Loss: 0.0237
Epoch [156/200], Loss: 0.0234
Epoch [157/200], Loss: 0.0234
Epoch [158/200], Loss: 0.0231
Epoch [159/200], Loss: 0.0230
Epoch [160/200], Loss: 0.0230
Epoch [161/200], Loss: 0.0228
Epoch [162/200], Loss: 0.0226
Epoch [163/200], Loss: 0.0225
Epoch [164/200], Loss: 0.0224
Epoch [165/200], Loss: 0.0223
Epoch [166/200], Loss: 0.0222
Epoch [167/200], Loss: 0.0221
Epoch [168/200], Loss: 0.0219
Epoch [169/200], Loss: 0.0218
Epoch [170/200], Loss: 0.0217
Epoch [171/200], Loss: 0.0216
Epoch [172/200], Loss: 0.0215
Epoch [173/200], Loss: 0.0214
Epoch [174/200], Loss: 0.0212
Epoch [175/200], Loss: 0.0211
Epoch [176/200], Loss: 0.0210
Epoch [177/200], Loss: 0.0209
Epoch [178/200], Loss: 0.0208
Epoch [179/200], Loss: 0.0208
Epoch [180/200], Loss: 0.0207
Epoch [181/200], Loss: 0.0206
Epoch [182/200], Loss: 0.0204
Epoch [183/200], Loss: 0.0203
Epoch [184/200], Loss: 0.0203
Epoch [185/200], Loss: 0.0202
Epoch [186/200], Loss: 0.0201
Epoch [187/200], Loss: 0.0200
Epoch [188/200], Loss: 0.0199
Epoch [189/200], Loss: 0.0199
Epoch [190/200], Loss: 0.0198
Epoch [191/200], Loss: 0.0197
Epoch [192/200], Loss: 0.0197
Epoch [193/200], Loss: 0.0195
Epoch [194/200], Loss: 0.0195
Epoch [195/200], Loss: 0.0194
Epoch [196/200], Loss: 0.0193
Epoch [197/200], Loss: 0.0192
Epoch [198/200], Loss: 0.0192
Epoch [199/200], Loss: 0.0191
Epoch [200/200], Loss: 0.0191

Evaluating Simple Neural Network (SNN)...
Test Accuracy: 97.53%

Evaluating Deep Neural Network without Regularization (DNN)...
Test Accuracy: 97.88%

Evaluating Deep Neural Network with L2 Regularization (DNN-Reg)...
Test Accuracy: 97.85%

Calculating AIC and EAIC for SNN...

Calculating AIC and EAIC for DNN...

Calculating AIC and EAIC for DNN-Reg...

===== Results =====
SNN Test Accuracy: 97.53%
SNN AIC: 209849.05, EAIC: 185645.05, Total Params: 101770, Effective Params: 89668

DNN Test Accuracy: 97.88%
DNN AIC: 485803.51, EAIC: 439973.51, Total Params: 242762, Effective Params: 219847

DNN-Reg Test Accuracy: 97.85%
DNN-Reg AIC: 487713.39, EAIC: 421195.39, Total Params: 242762, Effective Params: 209503

===== Correlation Analysis =====
Correlation between AIC and Test Accuracy: 99.65%
Correlation between EAIC and Test Accuracy: 99.99%
